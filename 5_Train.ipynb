{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991b5f9e",
   "metadata": {},
   "source": [
    "# ----------------------------------------定义训练函数-----------------------------------------------\n",
    "- 整合之前的函数进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b54db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Model_4.ipynb\n",
      "Namespace(model_path='models/', crop_size=224, vocab_path='data/vocab.pkl', image_dir='data/resized2014', caption_path='data/annotations/captions_train2014.json', log_step=10, save_step=1000, embed_size=256, hidden_size=512, num_layers=1, num_epochs=1, batch_size=128, num_workers=2, learning_rate=0.001)\n",
      "EncoderCNN(\n",
      "  (resnet): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (23): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (24): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (25): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (26): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (27): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (28): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (29): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (30): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (31): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (32): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (33): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (34): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (35): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (linear): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embed): Embedding(9948, 256)\n",
      "  (lstm): LSTM(256, 512, batch_first=True)\n",
      "  (linear): Linear(in_features=512, out_features=9948, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import import_ipynb\n",
    "# import Ipynb_importer\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "\n",
    "# from Data_Loader_3 import get_loader\n",
    "from Bulid_Vocab_2 import Vocabulary\n",
    "from Model_4 import EncoderCNN, DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "032de8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_path='models/', crop_size=224, vocab_path='data/vocab.pkl', image_dir='data/resized2014', caption_path='data/annotations/captions_train2014.json', log_step=10, save_step=1000, embed_size=256, hidden_size=512, num_layers=1, num_epochs=1, batch_size=128, num_workers=None, learning_rate=0.001)\n",
      "loading annotations into memory...\n",
      "Done (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "torch.Size([128, 3, 224, 224]) torch.Size([128, 22]) 128\n",
      "tensor([[   1,   33,   30,  ...,   47,   19,    2],\n",
      "        [   1,    4, 4666,  ...,    2,    0,    0],\n",
      "        [   1,   48, 1089,  ...,    2,    0,    0],\n",
      "        ...,\n",
      "        [   1,   51, 1312,  ...,    0,    0,    0],\n",
      "        [   1,   51,  744,  ...,    0,    0,    0],\n",
      "        [   1,    4,   92,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "from Data_Loader import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54de886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义使用GPU进行计算\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f32dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义训练函数\"\"\"\n",
    "def main(args):\n",
    "    # 检查模型路径是否存在, 不存在则创建\n",
    "    if not os.path.exists(args.model_path):\n",
    "        os.makedirs(args.model_path)\n",
    "    \n",
    "    # 定义图片的增广等操作\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(args.crop_size), # 随即裁剪到指定大小\n",
    "        transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
    "        transforms.ToTensor(), # 转成tensor\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)) # 标准化\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    # 加载词典\n",
    "    with open(args.vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    # 构建用于训练的数据包\n",
    "    data_loader = get_loader(args.image_dir, args.caption_path, vocab, transform, args.batch_size, \n",
    "                             shuffle=True, num_workers=args.num_workers)\n",
    "    \n",
    "    # 搭建模型\n",
    "    encoder = EncoderCNN(args.embed_size).to(device)\n",
    "    decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers).to(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=args.learning_rate)\n",
    "    \n",
    "    # 开始训练模型\n",
    "    total_step = len(data_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "            \n",
    "            # 设置小批量\n",
    "            images = images.to(device)\n",
    "            captions = captions.to(device)\n",
    "            targets = pack_padded_sequence(captions, lengths, batch_first=True)[0] # 把文本打包成一系列字节，为了处理不同长度的字符\n",
    "            \n",
    "            # 前向和反向传播，更新参数\n",
    "            features = encoder(images) # 提取输入图像的特征\n",
    "            outputs = decoder(features, captions, lengths) # 根据特征和源序列，及其有效填充长度计算预测结果\n",
    "            loss = criterion(outputs, targets) # 计算误差\n",
    "            decoder.zero_grad()\n",
    "            encoder.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 打印训练进度\n",
    "            if i % args.log_step == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss:{:.4f}, Perplexity:{:5.4f}'.format(epoch, args.num_epochs, i, \n",
    "                                                                                           total_step, loss.item(), np.exp(loss.item())))\n",
    "            \n",
    "            # 保存模型的检查点\n",
    "            if (i+1) % args.save_step == 0:\n",
    "                torch.save(decoder.state_dict(), os.path.join(args.model_path, 'decoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "                torch.save(encoder.state_dict(), os.path.join(args.model_path, 'encoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3febf016",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model_path MODEL_PATH] [--crop_size CROP_SIZE] [--vocab_path VOCAB_PATH]\n",
      "                             [--image_dir IMAGE_DIR] [--caption_path CAPTION_PATH] [--log_step LOG_STEP]\n",
      "                             [--save_step SAVE_STEP] [--embed_size EMBED_SIZE] [--hidden_size HIDDEN_SIZE]\n",
      "                             [--num_layers NUM_LAYERS] [--num_epochs NUM_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--num_workers NUM_WORKERS] [--learning_rate LEARNING_RATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\De\\AppData\\Roaming\\jupyter\\runtime\\kernel-ba5b0948-ea27-4431-b02d-6f7505e38844.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\De\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"定义参数，运行模型（在直接调用的情况下）\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #   创建一个命令行参数解析器对象，用于储存参数\n",
    "    parser = argparse.ArgumentParser() \n",
    "    \n",
    "    # 给定一些基础参数，包括文件路径等\n",
    "    parser.add_argument('--model_path', type=str, default='models/', help='保存训练模型的地方')\n",
    "    parser.add_argument('--crop_size', type=int, default=224, help='随机裁剪图片的大小')\n",
    "    parser.add_argument('--vocab_path', type=str, default='data/vocab.pkl', help='之前生成词典的路径')\n",
    "    parser.add_argument('--image_dir', type=str, default='data/resized2014', help='已经处理好大小的训练图片的路径')\n",
    "    parser.add_argument('--caption_path', type=str, default='data/annotations/captions_train2014.json',help='训练集标签的路径')\n",
    "    parser.add_argument('--log_step', type=int, default=10, help='打印训练进度的设定值')\n",
    "    parser.add_argument('--save_step', type=int, default=1000, help='保存模型节点的设定值')\n",
    "    \n",
    "    # 设定模型的参数值\n",
    "    parser.add_argument('--embed_size', type=int, default=256, help='词嵌入向量的维度，也就是用多少维来表示一个词元')\n",
    "    parser.add_argument('--hidden_size', type=int, default=512, help='隐藏状态的维度')\n",
    "    parser.add_argument('--num_layers', type=int, default=1, help='LSTM层的数量')\n",
    "    \n",
    "    # 设定训练的参数\n",
    "    parser.add_argument('--num_epochs', type=int, default=5, help='epoch数')\n",
    "    parser.add_argument('--batch_size', type=int, default=128, help='批量大小')\n",
    "    parser.add_argument('--num_workers', type=int, default=2, help='并行运算大小')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001, help='学习率')\n",
    "    \n",
    "    # 解析传入的命令行参数\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    \n",
    "    # 调用定义的main函数，传入已经解析后的参数\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a522d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_path='models/', crop_size=224, vocab_path='data/vocab.pkl', image_dir='data/resized2014', caption_path='data/annotations/captions_train2014.json', log_step=10, save_step=1000, embed_size=256, hidden_size=512, num_layers=1, num_epochs=1, batch_size=128, num_workers=0, learning_rate=0.001)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"创建一个命令行参数解析器对象，用于储存参数\"\"\"\n",
    "parser = argparse.ArgumentParser() \n",
    "\n",
    "# 给定一些基础参数，包括文件路径等\n",
    "parser.add_argument('--model_path', type=str, default='models/', help='保存训练模型的地方')\n",
    "parser.add_argument('--crop_size', type=int, default=224, help='随机裁剪图片的大小')\n",
    "parser.add_argument('--vocab_path', type=str, default='data/vocab.pkl', help='之前生成词典的路径')\n",
    "parser.add_argument('--image_dir', type=str, default='data/resized2014', help='已经处理好大小的训练图片的路径')\n",
    "parser.add_argument('--caption_path', type=str, default='data/annotations/captions_train2014.json',help='训练集标签的路径')\n",
    "parser.add_argument('--log_step', type=int, default=10, help='打印训练进度的设定值')\n",
    "parser.add_argument('--save_step', type=int, default=1000, help='保存模型节点的设定值')\n",
    "\n",
    "# 设定模型的参数值\n",
    "parser.add_argument('--embed_size', type=int, default=256, help='词嵌入向量的维度，也就是用多少维来表示一个词元')\n",
    "parser.add_argument('--hidden_size', type=int, default=512, help='隐藏状态的维度')\n",
    "parser.add_argument('--num_layers', type=int, default=1, help='LSTM层的数量')\n",
    "\n",
    "# 设定训练的参数\n",
    "parser.add_argument('--num_epochs', type=int, default=1, help='epoch数')\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='批量大小')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='并行运算大小')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='学习率')\n",
    "\n",
    "# 解析传入的命令行参数\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484e1c9",
   "metadata": {},
   "source": [
    "# -------------测试代码能否训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ea21488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查模型路径是否存在, 不存在则创建\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "166c9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图片的增广等操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(args.crop_size), # 随即裁剪到指定大小\n",
    "    transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
    "    transforms.ToTensor(), # 转成tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)) # 标准化\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c738a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载词典\n",
    "with open(args.vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a03b880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.50s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 构建用于训练的数据包\n",
    "data_loader = get_loader(args.image_dir, args.caption_path, vocab, transform, args.batch_size, \n",
    "                         shuffle=True, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcb8f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "encoder = EncoderCNN(args.embed_size).to(device)\n",
    "decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "830d5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=args.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927df77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b838c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beac292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1], Step [0/3236], Loss:9.1966, Perplexity:9863.5826\n",
      "Epoch [0/1], Step [10/3236], Loss:5.8161, Perplexity:335.6715\n",
      "Epoch [0/1], Step [20/3236], Loss:5.3998, Perplexity:221.3660\n",
      "Epoch [0/1], Step [30/3236], Loss:4.9297, Perplexity:138.3336\n",
      "Epoch [0/1], Step [40/3236], Loss:4.5931, Perplexity:98.8026\n",
      "Epoch [0/1], Step [50/3236], Loss:4.2968, Perplexity:73.4654\n",
      "Epoch [0/1], Step [60/3236], Loss:4.3751, Perplexity:79.4479\n",
      "Epoch [0/1], Step [70/3236], Loss:4.1304, Perplexity:62.2026\n",
      "Epoch [0/1], Step [80/3236], Loss:3.9044, Perplexity:49.6190\n",
      "Epoch [0/1], Step [90/3236], Loss:4.0232, Perplexity:55.8785\n",
      "Epoch [0/1], Step [100/3236], Loss:3.9092, Perplexity:49.8611\n",
      "Epoch [0/1], Step [110/3236], Loss:3.8121, Perplexity:45.2466\n",
      "Epoch [0/1], Step [120/3236], Loss:3.5910, Perplexity:36.2694\n",
      "Epoch [0/1], Step [130/3236], Loss:3.6123, Perplexity:37.0503\n",
      "Epoch [0/1], Step [140/3236], Loss:3.6877, Perplexity:39.9513\n",
      "Epoch [0/1], Step [150/3236], Loss:3.6752, Perplexity:39.4575\n",
      "Epoch [0/1], Step [160/3236], Loss:3.7113, Perplexity:40.9076\n",
      "Epoch [0/1], Step [170/3236], Loss:3.4337, Perplexity:30.9908\n",
      "Epoch [0/1], Step [180/3236], Loss:3.5429, Perplexity:34.5662\n",
      "Epoch [0/1], Step [190/3236], Loss:3.5132, Perplexity:33.5563\n",
      "Epoch [0/1], Step [200/3236], Loss:3.3781, Perplexity:29.3156\n",
      "Epoch [0/1], Step [210/3236], Loss:3.3097, Perplexity:27.3756\n",
      "Epoch [0/1], Step [220/3236], Loss:3.3468, Perplexity:28.4107\n",
      "Epoch [0/1], Step [230/3236], Loss:3.4366, Perplexity:31.0799\n",
      "Epoch [0/1], Step [240/3236], Loss:3.3181, Perplexity:27.6069\n",
      "Epoch [0/1], Step [250/3236], Loss:3.2277, Perplexity:25.2210\n",
      "Epoch [0/1], Step [260/3236], Loss:3.3148, Perplexity:27.5157\n",
      "Epoch [0/1], Step [270/3236], Loss:3.2449, Perplexity:25.6589\n",
      "Epoch [0/1], Step [280/3236], Loss:3.2989, Perplexity:27.0816\n",
      "Epoch [0/1], Step [290/3236], Loss:3.2459, Perplexity:25.6843\n",
      "Epoch [0/1], Step [300/3236], Loss:3.2159, Perplexity:24.9246\n",
      "Epoch [0/1], Step [310/3236], Loss:3.1381, Perplexity:23.0598\n",
      "Epoch [0/1], Step [320/3236], Loss:3.2119, Perplexity:24.8270\n",
      "Epoch [0/1], Step [330/3236], Loss:3.1083, Perplexity:22.3835\n",
      "Epoch [0/1], Step [340/3236], Loss:3.2364, Perplexity:25.4421\n",
      "Epoch [0/1], Step [350/3236], Loss:3.0984, Perplexity:22.1625\n",
      "Epoch [0/1], Step [360/3236], Loss:2.9899, Perplexity:19.8830\n",
      "Epoch [0/1], Step [370/3236], Loss:2.8770, Perplexity:17.7610\n",
      "Epoch [0/1], Step [380/3236], Loss:3.0832, Perplexity:21.8279\n",
      "Epoch [0/1], Step [390/3236], Loss:2.8283, Perplexity:16.9166\n",
      "Epoch [0/1], Step [400/3236], Loss:2.9475, Perplexity:19.0588\n",
      "Epoch [0/1], Step [410/3236], Loss:3.0623, Perplexity:21.3763\n",
      "Epoch [0/1], Step [420/3236], Loss:3.0746, Perplexity:21.6419\n",
      "Epoch [0/1], Step [430/3236], Loss:2.8787, Perplexity:17.7902\n",
      "Epoch [0/1], Step [440/3236], Loss:2.9377, Perplexity:18.8720\n",
      "Epoch [0/1], Step [450/3236], Loss:3.0599, Perplexity:21.3257\n",
      "Epoch [0/1], Step [460/3236], Loss:2.8375, Perplexity:17.0736\n",
      "Epoch [0/1], Step [470/3236], Loss:2.9702, Perplexity:19.4966\n",
      "Epoch [0/1], Step [480/3236], Loss:2.9316, Perplexity:18.7568\n",
      "Epoch [0/1], Step [490/3236], Loss:2.7756, Perplexity:16.0490\n",
      "Epoch [0/1], Step [500/3236], Loss:2.8552, Perplexity:17.3776\n",
      "Epoch [0/1], Step [510/3236], Loss:2.7839, Perplexity:16.1822\n",
      "Epoch [0/1], Step [520/3236], Loss:2.8564, Perplexity:17.3988\n",
      "Epoch [0/1], Step [530/3236], Loss:2.9370, Perplexity:18.8601\n",
      "Epoch [0/1], Step [540/3236], Loss:3.0668, Perplexity:21.4733\n",
      "Epoch [0/1], Step [550/3236], Loss:2.8630, Perplexity:17.5141\n",
      "Epoch [0/1], Step [560/3236], Loss:2.8291, Perplexity:16.9306\n",
      "Epoch [0/1], Step [570/3236], Loss:2.7175, Perplexity:15.1419\n",
      "Epoch [0/1], Step [580/3236], Loss:2.7435, Perplexity:15.5408\n",
      "Epoch [0/1], Step [590/3236], Loss:2.8154, Perplexity:16.6997\n",
      "Epoch [0/1], Step [600/3236], Loss:2.8792, Perplexity:17.8002\n",
      "Epoch [0/1], Step [610/3236], Loss:2.7763, Perplexity:16.0595\n",
      "Epoch [0/1], Step [620/3236], Loss:2.8722, Perplexity:17.6760\n",
      "Epoch [0/1], Step [630/3236], Loss:2.7673, Perplexity:15.9157\n",
      "Epoch [0/1], Step [640/3236], Loss:2.7768, Perplexity:16.0668\n",
      "Epoch [0/1], Step [650/3236], Loss:2.7086, Perplexity:15.0087\n",
      "Epoch [0/1], Step [660/3236], Loss:2.9018, Perplexity:18.2074\n",
      "Epoch [0/1], Step [670/3236], Loss:2.7871, Perplexity:16.2331\n",
      "Epoch [0/1], Step [680/3236], Loss:2.7162, Perplexity:15.1235\n",
      "Epoch [0/1], Step [690/3236], Loss:2.7252, Perplexity:15.2588\n",
      "Epoch [0/1], Step [700/3236], Loss:2.7667, Perplexity:15.9056\n",
      "Epoch [0/1], Step [710/3236], Loss:2.6606, Perplexity:14.3047\n",
      "Epoch [0/1], Step [720/3236], Loss:2.6470, Perplexity:14.1119\n",
      "Epoch [0/1], Step [730/3236], Loss:2.6608, Perplexity:14.3079\n",
      "Epoch [0/1], Step [740/3236], Loss:2.7199, Perplexity:15.1793\n",
      "Epoch [0/1], Step [750/3236], Loss:2.7488, Perplexity:15.6245\n",
      "Epoch [0/1], Step [760/3236], Loss:2.7314, Perplexity:15.3537\n",
      "Epoch [0/1], Step [770/3236], Loss:2.6463, Perplexity:14.1020\n",
      "Epoch [0/1], Step [780/3236], Loss:2.5517, Perplexity:12.8290\n",
      "Epoch [0/1], Step [790/3236], Loss:2.7524, Perplexity:15.6802\n",
      "Epoch [0/1], Step [800/3236], Loss:2.7607, Perplexity:15.8111\n",
      "Epoch [0/1], Step [810/3236], Loss:2.6294, Perplexity:13.8654\n",
      "Epoch [0/1], Step [820/3236], Loss:2.6037, Perplexity:13.5137\n",
      "Epoch [0/1], Step [830/3236], Loss:2.5559, Perplexity:12.8830\n",
      "Epoch [0/1], Step [840/3236], Loss:2.5302, Perplexity:12.5559\n",
      "Epoch [0/1], Step [850/3236], Loss:2.5903, Perplexity:13.3336\n",
      "Epoch [0/1], Step [860/3236], Loss:2.6740, Perplexity:14.4973\n",
      "Epoch [0/1], Step [870/3236], Loss:2.5947, Perplexity:13.3925\n",
      "Epoch [0/1], Step [880/3236], Loss:2.5347, Perplexity:12.6131\n",
      "Epoch [0/1], Step [890/3236], Loss:2.6876, Perplexity:14.6957\n",
      "Epoch [0/1], Step [900/3236], Loss:2.6226, Perplexity:13.7719\n",
      "Epoch [0/1], Step [910/3236], Loss:2.4850, Perplexity:12.0013\n",
      "Epoch [0/1], Step [920/3236], Loss:2.6111, Perplexity:13.6143\n",
      "Epoch [0/1], Step [930/3236], Loss:2.6281, Perplexity:13.8474\n",
      "Epoch [0/1], Step [940/3236], Loss:2.6974, Perplexity:14.8408\n",
      "Epoch [0/1], Step [950/3236], Loss:2.6747, Perplexity:14.5083\n",
      "Epoch [0/1], Step [960/3236], Loss:2.6699, Perplexity:14.4383\n",
      "Epoch [0/1], Step [970/3236], Loss:2.5823, Perplexity:13.2281\n",
      "Epoch [0/1], Step [980/3236], Loss:2.5327, Perplexity:12.5871\n",
      "Epoch [0/1], Step [990/3236], Loss:2.6114, Perplexity:13.6177\n",
      "Epoch [0/1], Step [1000/3236], Loss:2.5103, Perplexity:12.3083\n",
      "Epoch [0/1], Step [1010/3236], Loss:2.6222, Perplexity:13.7659\n",
      "Epoch [0/1], Step [1020/3236], Loss:2.5965, Perplexity:13.4166\n",
      "Epoch [0/1], Step [1030/3236], Loss:2.6444, Perplexity:14.0748\n",
      "Epoch [0/1], Step [1040/3236], Loss:2.7322, Perplexity:15.3670\n",
      "Epoch [0/1], Step [1050/3236], Loss:2.5287, Perplexity:12.5367\n",
      "Epoch [0/1], Step [1060/3236], Loss:2.5401, Perplexity:12.6811\n",
      "Epoch [0/1], Step [1070/3236], Loss:2.5233, Perplexity:12.4702\n",
      "Epoch [0/1], Step [1080/3236], Loss:2.4065, Perplexity:11.0949\n",
      "Epoch [0/1], Step [1090/3236], Loss:2.4434, Perplexity:11.5126\n",
      "Epoch [0/1], Step [1100/3236], Loss:2.5084, Perplexity:12.2852\n",
      "Epoch [0/1], Step [1110/3236], Loss:2.6834, Perplexity:14.6345\n",
      "Epoch [0/1], Step [1120/3236], Loss:2.4836, Perplexity:11.9847\n",
      "Epoch [0/1], Step [1130/3236], Loss:2.4846, Perplexity:11.9965\n",
      "Epoch [0/1], Step [1140/3236], Loss:2.5906, Perplexity:13.3378\n",
      "Epoch [0/1], Step [1150/3236], Loss:2.5334, Perplexity:12.5964\n",
      "Epoch [0/1], Step [1160/3236], Loss:2.4347, Perplexity:11.4119\n",
      "Epoch [0/1], Step [1170/3236], Loss:2.6001, Perplexity:13.4651\n",
      "Epoch [0/1], Step [1180/3236], Loss:2.5087, Perplexity:12.2889\n",
      "Epoch [0/1], Step [1190/3236], Loss:2.4109, Perplexity:11.1441\n",
      "Epoch [0/1], Step [1200/3236], Loss:2.5859, Perplexity:13.2746\n",
      "Epoch [0/1], Step [1210/3236], Loss:2.6470, Perplexity:14.1119\n",
      "Epoch [0/1], Step [1220/3236], Loss:2.4247, Perplexity:11.2984\n",
      "Epoch [0/1], Step [1230/3236], Loss:2.5338, Perplexity:12.6013\n",
      "Epoch [0/1], Step [1240/3236], Loss:2.3505, Perplexity:10.4903\n",
      "Epoch [0/1], Step [1250/3236], Loss:2.3962, Perplexity:10.9809\n",
      "Epoch [0/1], Step [1260/3236], Loss:2.3839, Perplexity:10.8470\n",
      "Epoch [0/1], Step [1270/3236], Loss:2.3832, Perplexity:10.8393\n",
      "Epoch [0/1], Step [1280/3236], Loss:2.4320, Perplexity:11.3813\n",
      "Epoch [0/1], Step [1290/3236], Loss:2.4842, Perplexity:11.9910\n",
      "Epoch [0/1], Step [1300/3236], Loss:2.5496, Perplexity:12.8015\n",
      "Epoch [0/1], Step [1310/3236], Loss:2.3362, Perplexity:10.3420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1], Step [1320/3236], Loss:2.5824, Perplexity:13.2287\n",
      "Epoch [0/1], Step [1330/3236], Loss:2.4119, Perplexity:11.1557\n",
      "Epoch [0/1], Step [1340/3236], Loss:2.4681, Perplexity:11.7997\n",
      "Epoch [0/1], Step [1350/3236], Loss:2.4057, Perplexity:11.0858\n",
      "Epoch [0/1], Step [1360/3236], Loss:2.3511, Perplexity:10.4972\n",
      "Epoch [0/1], Step [1370/3236], Loss:2.4997, Perplexity:12.1790\n",
      "Epoch [0/1], Step [1380/3236], Loss:2.4144, Perplexity:11.1835\n",
      "Epoch [0/1], Step [1390/3236], Loss:2.3850, Perplexity:10.8586\n",
      "Epoch [0/1], Step [1400/3236], Loss:2.5625, Perplexity:12.9684\n",
      "Epoch [0/1], Step [1410/3236], Loss:2.4460, Perplexity:11.5416\n",
      "Epoch [0/1], Step [1420/3236], Loss:2.4147, Perplexity:11.1864\n",
      "Epoch [0/1], Step [1430/3236], Loss:2.4680, Perplexity:11.7993\n",
      "Epoch [0/1], Step [1440/3236], Loss:2.5056, Perplexity:12.2514\n",
      "Epoch [0/1], Step [1450/3236], Loss:2.4803, Perplexity:11.9454\n",
      "Epoch [0/1], Step [1460/3236], Loss:2.5564, Perplexity:12.8897\n",
      "Epoch [0/1], Step [1470/3236], Loss:2.5190, Perplexity:12.4160\n",
      "Epoch [0/1], Step [1480/3236], Loss:2.3507, Perplexity:10.4934\n",
      "Epoch [0/1], Step [1490/3236], Loss:2.3584, Perplexity:10.5742\n",
      "Epoch [0/1], Step [1500/3236], Loss:2.6593, Perplexity:14.2869\n",
      "Epoch [0/1], Step [1510/3236], Loss:2.3798, Perplexity:10.8024\n",
      "Epoch [0/1], Step [1520/3236], Loss:2.4892, Perplexity:12.0510\n",
      "Epoch [0/1], Step [1530/3236], Loss:2.3354, Perplexity:10.3336\n",
      "Epoch [0/1], Step [1540/3236], Loss:2.4630, Perplexity:11.7402\n",
      "Epoch [0/1], Step [1550/3236], Loss:2.3236, Perplexity:10.2119\n",
      "Epoch [0/1], Step [1560/3236], Loss:2.4573, Perplexity:11.6731\n",
      "Epoch [0/1], Step [1570/3236], Loss:2.4350, Perplexity:11.4156\n",
      "Epoch [0/1], Step [1580/3236], Loss:2.3926, Perplexity:10.9419\n",
      "Epoch [0/1], Step [1590/3236], Loss:2.4655, Perplexity:11.7698\n",
      "Epoch [0/1], Step [1600/3236], Loss:2.4996, Perplexity:12.1779\n",
      "Epoch [0/1], Step [1610/3236], Loss:2.3033, Perplexity:10.0069\n",
      "Epoch [0/1], Step [1620/3236], Loss:2.4536, Perplexity:11.6300\n",
      "Epoch [0/1], Step [1630/3236], Loss:2.5992, Perplexity:13.4524\n",
      "Epoch [0/1], Step [1640/3236], Loss:2.3581, Perplexity:10.5708\n",
      "Epoch [0/1], Step [1650/3236], Loss:2.5313, Perplexity:12.5697\n",
      "Epoch [0/1], Step [1660/3236], Loss:2.4032, Perplexity:11.0583\n",
      "Epoch [0/1], Step [1670/3236], Loss:2.4530, Perplexity:11.6231\n",
      "Epoch [0/1], Step [1680/3236], Loss:2.3812, Perplexity:10.8178\n",
      "Epoch [0/1], Step [1690/3236], Loss:2.3603, Perplexity:10.5941\n",
      "Epoch [0/1], Step [1700/3236], Loss:2.5937, Perplexity:13.3790\n",
      "Epoch [0/1], Step [1710/3236], Loss:2.3790, Perplexity:10.7942\n",
      "Epoch [0/1], Step [1720/3236], Loss:2.3740, Perplexity:10.7400\n",
      "Epoch [0/1], Step [1730/3236], Loss:2.3746, Perplexity:10.7471\n",
      "Epoch [0/1], Step [1740/3236], Loss:2.3348, Perplexity:10.3275\n",
      "Epoch [0/1], Step [1750/3236], Loss:2.3559, Perplexity:10.5481\n",
      "Epoch [0/1], Step [1760/3236], Loss:2.4778, Perplexity:11.9154\n",
      "Epoch [0/1], Step [1770/3236], Loss:2.5076, Perplexity:12.2755\n",
      "Epoch [0/1], Step [1780/3236], Loss:2.5037, Perplexity:12.2280\n",
      "Epoch [0/1], Step [1790/3236], Loss:2.4192, Perplexity:11.2372\n",
      "Epoch [0/1], Step [1800/3236], Loss:2.3187, Perplexity:10.1621\n",
      "Epoch [0/1], Step [1810/3236], Loss:2.5207, Perplexity:12.4372\n",
      "Epoch [0/1], Step [1820/3236], Loss:2.4706, Perplexity:11.8292\n",
      "Epoch [0/1], Step [1830/3236], Loss:2.3320, Perplexity:10.2987\n",
      "Epoch [0/1], Step [1840/3236], Loss:2.4200, Perplexity:11.2457\n",
      "Epoch [0/1], Step [1850/3236], Loss:2.4639, Perplexity:11.7504\n",
      "Epoch [0/1], Step [1860/3236], Loss:2.3319, Perplexity:10.2980\n",
      "Epoch [0/1], Step [1870/3236], Loss:2.3404, Perplexity:10.3853\n",
      "Epoch [0/1], Step [1880/3236], Loss:2.3589, Perplexity:10.5789\n",
      "Epoch [0/1], Step [1890/3236], Loss:2.3874, Perplexity:10.8851\n",
      "Epoch [0/1], Step [1900/3236], Loss:2.4263, Perplexity:11.3170\n",
      "Epoch [0/1], Step [1910/3236], Loss:2.4126, Perplexity:11.1629\n",
      "Epoch [0/1], Step [1920/3236], Loss:2.5318, Perplexity:12.5759\n",
      "Epoch [0/1], Step [1930/3236], Loss:2.3435, Perplexity:10.4178\n",
      "Epoch [0/1], Step [1940/3236], Loss:2.3922, Perplexity:10.9374\n",
      "Epoch [0/1], Step [1950/3236], Loss:2.3286, Perplexity:10.2640\n",
      "Epoch [0/1], Step [1960/3236], Loss:2.3349, Perplexity:10.3287\n",
      "Epoch [0/1], Step [1970/3236], Loss:2.3551, Perplexity:10.5393\n",
      "Epoch [0/1], Step [1980/3236], Loss:2.4836, Perplexity:11.9849\n",
      "Epoch [0/1], Step [1990/3236], Loss:2.2131, Perplexity:9.1441\n",
      "Epoch [0/1], Step [2000/3236], Loss:2.2750, Perplexity:9.7283\n",
      "Epoch [0/1], Step [2010/3236], Loss:2.3339, Perplexity:10.3183\n",
      "Epoch [0/1], Step [2020/3236], Loss:2.3643, Perplexity:10.6370\n",
      "Epoch [0/1], Step [2030/3236], Loss:2.2799, Perplexity:9.7761\n",
      "Epoch [0/1], Step [2040/3236], Loss:2.3626, Perplexity:10.6181\n",
      "Epoch [0/1], Step [2050/3236], Loss:2.3742, Perplexity:10.7428\n",
      "Epoch [0/1], Step [2060/3236], Loss:2.3574, Perplexity:10.5629\n",
      "Epoch [0/1], Step [2070/3236], Loss:2.1678, Perplexity:8.7389\n",
      "Epoch [0/1], Step [2080/3236], Loss:2.3569, Perplexity:10.5579\n",
      "Epoch [0/1], Step [2090/3236], Loss:2.3740, Perplexity:10.7407\n",
      "Epoch [0/1], Step [2100/3236], Loss:2.2934, Perplexity:9.9082\n",
      "Epoch [0/1], Step [2110/3236], Loss:2.4431, Perplexity:11.5085\n",
      "Epoch [0/1], Step [2120/3236], Loss:2.2121, Perplexity:9.1347\n",
      "Epoch [0/1], Step [2130/3236], Loss:2.3483, Perplexity:10.4674\n",
      "Epoch [0/1], Step [2140/3236], Loss:2.4151, Perplexity:11.1909\n",
      "Epoch [0/1], Step [2150/3236], Loss:2.3636, Perplexity:10.6294\n",
      "Epoch [0/1], Step [2160/3236], Loss:2.4067, Perplexity:11.0970\n",
      "Epoch [0/1], Step [2170/3236], Loss:2.2813, Perplexity:9.7898\n",
      "Epoch [0/1], Step [2180/3236], Loss:2.2912, Perplexity:9.8867\n",
      "Epoch [0/1], Step [2190/3236], Loss:2.4032, Perplexity:11.0585\n",
      "Epoch [0/1], Step [2200/3236], Loss:2.4077, Perplexity:11.1088\n",
      "Epoch [0/1], Step [2210/3236], Loss:2.3668, Perplexity:10.6635\n",
      "Epoch [0/1], Step [2220/3236], Loss:2.4140, Perplexity:11.1790\n",
      "Epoch [0/1], Step [2230/3236], Loss:2.4566, Perplexity:11.6650\n",
      "Epoch [0/1], Step [2240/3236], Loss:2.4305, Perplexity:11.3640\n",
      "Epoch [0/1], Step [2250/3236], Loss:2.3066, Perplexity:10.0398\n",
      "Epoch [0/1], Step [2260/3236], Loss:2.3543, Perplexity:10.5307\n",
      "Epoch [0/1], Step [2270/3236], Loss:2.3291, Perplexity:10.2685\n",
      "Epoch [0/1], Step [2280/3236], Loss:2.3799, Perplexity:10.8043\n",
      "Epoch [0/1], Step [2290/3236], Loss:2.1954, Perplexity:8.9836\n",
      "Epoch [0/1], Step [2300/3236], Loss:2.4221, Perplexity:11.2690\n",
      "Epoch [0/1], Step [2310/3236], Loss:2.2749, Perplexity:9.7265\n",
      "Epoch [0/1], Step [2320/3236], Loss:2.3957, Perplexity:10.9758\n",
      "Epoch [0/1], Step [2330/3236], Loss:2.3493, Perplexity:10.4780\n",
      "Epoch [0/1], Step [2340/3236], Loss:2.3591, Perplexity:10.5813\n",
      "Epoch [0/1], Step [2350/3236], Loss:2.3300, Perplexity:10.2776\n",
      "Epoch [0/1], Step [2360/3236], Loss:2.3161, Perplexity:10.1357\n",
      "Epoch [0/1], Step [2370/3236], Loss:2.3120, Perplexity:10.0942\n",
      "Epoch [0/1], Step [2380/3236], Loss:2.2813, Perplexity:9.7898\n",
      "Epoch [0/1], Step [2390/3236], Loss:2.4217, Perplexity:11.2647\n",
      "Epoch [0/1], Step [2400/3236], Loss:2.2542, Perplexity:9.5281\n",
      "Epoch [0/1], Step [2410/3236], Loss:2.3326, Perplexity:10.3051\n",
      "Epoch [0/1], Step [2420/3236], Loss:2.4293, Perplexity:11.3512\n",
      "Epoch [0/1], Step [2430/3236], Loss:2.2421, Perplexity:9.4129\n",
      "Epoch [0/1], Step [2440/3236], Loss:2.2595, Perplexity:9.5784\n",
      "Epoch [0/1], Step [2450/3236], Loss:2.3123, Perplexity:10.0972\n",
      "Epoch [0/1], Step [2460/3236], Loss:2.2032, Perplexity:9.0539\n",
      "Epoch [0/1], Step [2470/3236], Loss:2.4647, Perplexity:11.7596\n",
      "Epoch [0/1], Step [2480/3236], Loss:2.4799, Perplexity:11.9406\n",
      "Epoch [0/1], Step [2490/3236], Loss:2.3847, Perplexity:10.8556\n",
      "Epoch [0/1], Step [2500/3236], Loss:2.4049, Perplexity:11.0773\n",
      "Epoch [0/1], Step [2510/3236], Loss:2.3461, Perplexity:10.4451\n",
      "Epoch [0/1], Step [2520/3236], Loss:2.1608, Perplexity:8.6785\n",
      "Epoch [0/1], Step [2530/3236], Loss:2.2967, Perplexity:9.9409\n",
      "Epoch [0/1], Step [2540/3236], Loss:2.3433, Perplexity:10.4152\n",
      "Epoch [0/1], Step [2550/3236], Loss:2.3228, Perplexity:10.2042\n",
      "Epoch [0/1], Step [2560/3236], Loss:2.3400, Perplexity:10.3814\n",
      "Epoch [0/1], Step [2570/3236], Loss:2.2737, Perplexity:9.7156\n",
      "Epoch [0/1], Step [2580/3236], Loss:2.2768, Perplexity:9.7451\n",
      "Epoch [0/1], Step [2590/3236], Loss:2.2330, Perplexity:9.3276\n",
      "Epoch [0/1], Step [2600/3236], Loss:2.2180, Perplexity:9.1891\n",
      "Epoch [0/1], Step [2610/3236], Loss:2.3896, Perplexity:10.9093\n",
      "Epoch [0/1], Step [2620/3236], Loss:2.1869, Perplexity:8.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1], Step [2630/3236], Loss:2.2105, Perplexity:9.1206\n",
      "Epoch [0/1], Step [2640/3236], Loss:2.3842, Perplexity:10.8504\n",
      "Epoch [0/1], Step [2650/3236], Loss:2.2508, Perplexity:9.4953\n",
      "Epoch [0/1], Step [2660/3236], Loss:2.1967, Perplexity:8.9950\n",
      "Epoch [0/1], Step [2670/3236], Loss:2.2068, Perplexity:9.0862\n",
      "Epoch [0/1], Step [2680/3236], Loss:2.2006, Perplexity:9.0301\n",
      "Epoch [0/1], Step [2690/3236], Loss:2.3353, Perplexity:10.3329\n",
      "Epoch [0/1], Step [2700/3236], Loss:2.2844, Perplexity:9.8202\n",
      "Epoch [0/1], Step [2710/3236], Loss:2.2502, Perplexity:9.4896\n",
      "Epoch [0/1], Step [2720/3236], Loss:2.3878, Perplexity:10.8899\n",
      "Epoch [0/1], Step [2730/3236], Loss:2.3558, Perplexity:10.5470\n",
      "Epoch [0/1], Step [2740/3236], Loss:2.2775, Perplexity:9.7524\n",
      "Epoch [0/1], Step [2750/3236], Loss:2.3189, Perplexity:10.1649\n",
      "Epoch [0/1], Step [2760/3236], Loss:2.3845, Perplexity:10.8538\n",
      "Epoch [0/1], Step [2770/3236], Loss:2.0946, Perplexity:8.1219\n",
      "Epoch [0/1], Step [2780/3236], Loss:2.3633, Perplexity:10.6265\n",
      "Epoch [0/1], Step [2790/3236], Loss:2.2333, Perplexity:9.3305\n",
      "Epoch [0/1], Step [2800/3236], Loss:2.2884, Perplexity:9.8588\n",
      "Epoch [0/1], Step [2810/3236], Loss:2.2730, Perplexity:9.7085\n",
      "Epoch [0/1], Step [2820/3236], Loss:2.2249, Perplexity:9.2522\n",
      "Epoch [0/1], Step [2830/3236], Loss:2.3905, Perplexity:10.9193\n",
      "Epoch [0/1], Step [2840/3236], Loss:2.2541, Perplexity:9.5271\n",
      "Epoch [0/1], Step [2850/3236], Loss:2.3283, Perplexity:10.2607\n",
      "Epoch [0/1], Step [2860/3236], Loss:2.2961, Perplexity:9.9358\n",
      "Epoch [0/1], Step [2870/3236], Loss:2.1713, Perplexity:8.7697\n",
      "Epoch [0/1], Step [2880/3236], Loss:2.1972, Perplexity:8.9998\n",
      "Epoch [0/1], Step [2890/3236], Loss:2.1806, Perplexity:8.8515\n",
      "Epoch [0/1], Step [2900/3236], Loss:2.2418, Perplexity:9.4106\n",
      "Epoch [0/1], Step [2910/3236], Loss:2.2556, Perplexity:9.5412\n",
      "Epoch [0/1], Step [2920/3236], Loss:2.4148, Perplexity:11.1876\n",
      "Epoch [0/1], Step [2930/3236], Loss:2.1514, Perplexity:8.5972\n",
      "Epoch [0/1], Step [2940/3236], Loss:2.3923, Perplexity:10.9382\n",
      "Epoch [0/1], Step [2950/3236], Loss:2.2973, Perplexity:9.9470\n",
      "Epoch [0/1], Step [2960/3236], Loss:2.4001, Perplexity:11.0247\n",
      "Epoch [0/1], Step [2970/3236], Loss:2.2835, Perplexity:9.8114\n",
      "Epoch [0/1], Step [2980/3236], Loss:2.2559, Perplexity:9.5440\n",
      "Epoch [0/1], Step [2990/3236], Loss:2.3099, Perplexity:10.0731\n",
      "Epoch [0/1], Step [3000/3236], Loss:2.2702, Perplexity:9.6815\n",
      "Epoch [0/1], Step [3010/3236], Loss:2.3556, Perplexity:10.5441\n",
      "Epoch [0/1], Step [3020/3236], Loss:2.3990, Perplexity:11.0123\n",
      "Epoch [0/1], Step [3030/3236], Loss:2.1979, Perplexity:9.0061\n",
      "Epoch [0/1], Step [3040/3236], Loss:2.2119, Perplexity:9.1328\n",
      "Epoch [0/1], Step [3050/3236], Loss:2.2832, Perplexity:9.8081\n",
      "Epoch [0/1], Step [3060/3236], Loss:2.2131, Perplexity:9.1438\n",
      "Epoch [0/1], Step [3070/3236], Loss:2.1360, Perplexity:8.4655\n",
      "Epoch [0/1], Step [3080/3236], Loss:2.2051, Perplexity:9.0710\n",
      "Epoch [0/1], Step [3090/3236], Loss:2.2429, Perplexity:9.4208\n",
      "Epoch [0/1], Step [3100/3236], Loss:2.3036, Perplexity:10.0106\n",
      "Epoch [0/1], Step [3110/3236], Loss:2.3596, Perplexity:10.5872\n",
      "Epoch [0/1], Step [3120/3236], Loss:2.4596, Perplexity:11.7000\n",
      "Epoch [0/1], Step [3130/3236], Loss:2.1217, Perplexity:8.3455\n",
      "Epoch [0/1], Step [3140/3236], Loss:2.2550, Perplexity:9.5356\n",
      "Epoch [0/1], Step [3150/3236], Loss:2.1191, Perplexity:8.3233\n",
      "Epoch [0/1], Step [3160/3236], Loss:2.3028, Perplexity:10.0022\n",
      "Epoch [0/1], Step [3170/3236], Loss:2.1928, Perplexity:8.9605\n",
      "Epoch [0/1], Step [3180/3236], Loss:2.3494, Perplexity:10.4792\n",
      "Epoch [0/1], Step [3190/3236], Loss:2.2156, Perplexity:9.1670\n",
      "Epoch [0/1], Step [3200/3236], Loss:2.2669, Perplexity:9.6491\n",
      "Epoch [0/1], Step [3210/3236], Loss:2.0186, Perplexity:7.5279\n",
      "Epoch [0/1], Step [3220/3236], Loss:2.1827, Perplexity:8.8703\n",
      "Epoch [0/1], Step [3230/3236], Loss:2.4138, Perplexity:11.1760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 开始训练模型\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(args.num_epochs):\n",
    "    for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "\n",
    "        # 设置小批量\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0] # 把文本打包成一系列字节，为了处理不同长度的字符\n",
    "\n",
    "        # 前向和反向传播，更新参数\n",
    "        features = encoder(images) # 提取输入图像的特征\n",
    "        outputs = decoder(features, captions, lengths) # 根据特征和源序列，及其有效填充长度计算预测结果\n",
    "        loss = criterion(outputs, targets) # 计算误差\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印训练进度\n",
    "        if i % args.log_step == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss:{:.4f}, Perplexity:{:5.4f}'.format(epoch, args.num_epochs, i, \n",
    "                                                                                       total_step, loss.item(), np.exp(loss.item())))\n",
    "\n",
    "        # 保存模型的检查点\n",
    "        if (i+1) % args.save_step == 0:\n",
    "            torch.save(decoder.state_dict(), os.path.join(args.model_path, 'decoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "            torch.save(encoder.state_dict(), os.path.join(args.model_path, 'encoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98b055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_zzh",
   "language": "python",
   "name": "machine_zzh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
